# Importing necessary libraries
import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D

# Load Fashion MNIST dataset using TensorFlow Datasets (TFDS)
(ds_train) = tfds.load('fashion_mnist', split=['train[:80%]', 'train[80%:]'], as_supervised=True)

# Load Fashion MNIST dataset
(ds_train)= tf.keras.datasets.fashion_mnist.load_data()
ds_train = ds_train / 255.0  # Normalize pixel values to [0, 1]
ds_train = ds_train.reshape(ds_train.shape[0], 28, 28, 1).astype('float32')

# Build the generator
def build_generator():
    model = Sequential()
    model.add(Dense(7*7*128, input_dim=128))
    model.add(LeakyReLU(0.2))
    model.add(Reshape((7, 7, 128)))
    model.add(UpSampling2D())
    model.add(Conv2D(128, 5, padding='same'))
    model.add(LeakyReLU(0.2))
    model.add(UpSampling2D())
    model.add(Conv2D(128, 5, padding='same'))
    model.add(LeakyReLU(0.2))
    model.add(Conv2D(1, 4, padding='same', activation='sigmoid'))
    return model

# Build the discriminator
def build_discriminator():
    model = Sequential()
    model.add(Conv2D(32, 5, input_shape=(28, 28, 1)))
    model.add(LeakyReLU(0.2))
    model.add(Dropout(0.4))
    model.add(Conv2D(64, 5))
    model.add(LeakyReLU(0.2))
    model.add(Dropout(0.4))
    model.add(Conv2D(128, 5))
    model.add(LeakyReLU(0.2))
    model.add(Dropout(0.4))
    model.add(Conv2D(256, 5))
    model.add(LeakyReLU(0.2))
    model.add(Dropout(0.4))
    model.add(Flatten())
    model.add(Dropout(0.4))
    model.add(Dense(1, activation='sigmoid'))
    return model

# Build the GAN model
def build_gan(generator, discriminator):
    discriminator.trainable = False
    model = Sequential()
    model.add(generator)
    model.add(discriminator)
    return model

# Compile models
generator = build_generator()
discriminator = build_discriminator()
gan = build_gan(generator, discriminator)

discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
gan.compile(optimizer='adam', loss='binary_crossentropy')

# Training loop
def train_gan(generator, discriminator, gan, dataset, epochs=1, batch_size=128):
    for epoch in range(epochs):
        for _ in range(dataset.shape[0] // batch_size):
            noise = tf.random.normal([batch_size, 128])
            generated_images = generator.predict(noise)
            labels_real = tf.ones((batch_size, 1))
            labels_fake = tf.zeros((batch_size, 1))

            d_loss_real = discriminator.train_on_batch(dataset, labels_real)
            d_loss_fake = discriminator.train_on_batch(generated_images, labels_fake)

            d_loss = 0.5 * tf.math.add(d_loss_real, d_loss_fake)

            noise = tf.random.normal([batch_size, 128])
            labels_gan = tf.ones((batch_size, 1))

            g_loss = gan.train_on_batch(noise, labels_gan)

        print(f"Epoch {epoch + 1}, D Loss: {d_loss[0]}, G Loss: {g_loss}")

# Train the GAN
train_gan(generator, discriminator, gan, ds_train, epochs=50, batch_size=128)










