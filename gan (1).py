# -*- coding: utf-8 -*-
"""GAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15mZERCyI9fGhU0Y4nmGmkDr6b2h_yzhJ
"""

#importing dependencies and data

pip install tensorflow tensorflow-gpu matplotlib tensorflow-datasets ipywidgets

pip install --upgrade pip

# Commented out IPython magic to ensure Python compatibility.
# %pip install tensorflow-gpu

pip install tensorflow tensorflow-gpu matplotlib tensorflow-datasets ipywidgets

pip list

import tensorflow as tf
gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
  tf.config.experimental.set_memory_growth(gpu,True)

gpus

for gpu in gpus:
  print (gpu)

# bringing in tensorflow dataset for fashion mnist
import tensorflow_datasets as tfds
# bringing in matplotlib for vis stuff
from matplotlib import pyplot as plt

# use the tesorflow dataset api to bring in the data source
ds = tfds.load('fashion_mnist',split='train')

ds.as_numpy_iterator().next()['label']

"""vis data and build dataset

"""

# do some data transformation
import numpy as np

dataiterator = ds.as_numpy_iterator()

#getting data out of the pipline
dataiterator.next()['image']

#set up the subplot formating
fig,ax = plt.subplots(ncols=4, figsize=(20,20))
# loop four times and get images
for idx in range(4):
  #grab an image and lable
  sample = dataiterator.next()
 #plot a image using a spicific axies
ax[idx].imshow(np.squeeze(sample['image']))
#appending the image label as the plot title
ax[idx].title.set_text(sample['label'])

def scale_images(data):
  image = data['image']
  return image / 255

ds = tfds.load('fashion_mnist',split='train')
# running the dataset through the scale image preprocessing steps
ds = ds.map(scale_images)
#cache the dataset for that batch
ds = ds.cache()
#shuffle it up
ds = ds.shuffle(60000)
# batch into 128 image per sample
ds = ds.batch(128)
#reduce the likelihood of bottleneacking
ds = ds.prefetch(64)

ds.as_numpy_iterator().next().shape



"""building a MODEL"""

# importing modeling compenents

#Bring in the sequential api for the generater and discriminator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D

# building a generator

def build_generator():
    model = Sequential()
    # takes in random values and reshape it to 7*7*128
    # beginning of a generated image
    model.add(Dense(7*7*128, input_dim=128))
    model.add(LeakyReLU(0.2))
    model.add(Reshape((7, 7, 128)))

    # upsampling block1
    model.add(UpSampling2D())
    model.add(Conv2D(128, 5, padding='same'))
    model.add(LeakyReLU(0.2))

    # upsampling block 2
    model.add(UpSampling2D())
    model.add(Conv2D(128, 5, padding='same'))
    model.add(LeakyReLU(0.2))

    #Convoluctional  block1
    model.add(Conv2D(128, 4, padding='same'))
    model.add(LeakyReLU(0.2))

    # Convoluctional block2
    model.add(Conv2D(128, 4, padding='same'))
    model.add(LeakyReLU(0.2))

    # conv layer to get into one channel
    model.add(Conv2D(1, 4, padding='same', activation='sigmoid'))
    return model

generator= build_generator()

generator.summary()

img = generator.predict(np.random.randn(4,128,1))
img

img.shape

#set up the subplot formating
fig,ax = plt.subplots(ncols=4, figsize=(20,20))
# loop four times and get images
for idx,img in enumerate(img):
 #plot a image using a spicific axies
    ax[idx].imshow(np.squeeze(img))
#appending the image label as the plot title
    ax[idx].title.set_text(idx)

# building a discriminator

from keras.src.metrics.confusion_metrics import activations
def build_discriminator():
  model = Sequential()
  #Fist conv block
  model.add(Conv2D(32,5,input_shape=(28,28,1)))
  model.add(LeakyReLU(0.2))
  model.add(Dropout(0.4))
  #second Conv block
  model.add(Conv2D(64,5))
  model.add(LeakyReLU(0.2))
  model.add(Dropout(0.4))
  #third Conv block
  model.add(Conv2D(128,5))
  model.add(LeakyReLU(0.2))
  model.add(Dropout(0.4))
  #FourtConv block
  model.add(Conv2D(256,5))
  model.add(LeakyReLU(0.2))
  model.add(Dropout(0.4))
  #Flatten then pass to dence layers
  model.add(Flatten())
  model.add(Dropout(0.4))
  model.add(Dense(1,activation='sigmoid'))
  return model

discriminator = build_discriminator()

discriminator.summary()

img = img[0]

discriminator.predict(img)









